{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Code in this block based on: https://github.com/cmcguinness/focusstack\n",
    "# The algorithm it uses is inspired by the high-level description given at:\n",
    "# http://stackoverflow.com/questions/15911783/what-are-some-common-focus-stacking-algorithms\n",
    "\n",
    "def findHomography(image_1_kp, image_2_kp, matches):\n",
    "    image_1_points = np.zeros((len(matches), 1, 2), dtype=np.float32)\n",
    "    image_2_points = np.zeros((len(matches), 1, 2), dtype=np.float32)\n",
    "\n",
    "    for i in range(0,len(matches)):\n",
    "        image_1_points[i] = image_1_kp[matches[i].queryIdx].pt\n",
    "        image_2_points[i] = image_2_kp[matches[i].trainIdx].pt\n",
    "\n",
    "    homography, mask = cv2.findHomography(image_1_points, image_2_points, cv2.RANSAC, ransacReprojThreshold=2.0)\n",
    "\n",
    "    return homography\n",
    "\n",
    "#   Align the images so they overlap properly...\n",
    "def align_images(images):\n",
    "    #   SIFT generally produces better results, but it is not FOSS, so chose the feature detector\n",
    "    #   that suits the needs of your project.  ORB does OK\n",
    "    use_sift = True\n",
    "    outimages = []\n",
    "\n",
    "    if use_sift:\n",
    "        detector = cv2.xfeatures2d.SIFT_create()\n",
    "    else:\n",
    "        detector = cv2.ORB_create(1000)\n",
    "\n",
    "    #   We assume that image 0 is the \"base\" image and align everything to it\n",
    "    print(\"Detecting features of base image\")\n",
    "    outimages.append(images[0])\n",
    "    image1gray = cv2.cvtColor(images[0],cv2.COLOR_BGR2GRAY)\n",
    "    image_1_kp, image_1_desc = detector.detectAndCompute(image1gray, None)\n",
    "\n",
    "    for i in range(1,len(images)):\n",
    "        print(\"Aligning image {}\".format(i))\n",
    "        image_i_kp, image_i_desc = detector.detectAndCompute(images[i], None)\n",
    "\n",
    "        if use_sift:\n",
    "            bf = cv2.BFMatcher()\n",
    "            # This returns the top two matches for each feature point (list of list)\n",
    "            pairMatches = bf.knnMatch(image_i_desc,image_1_desc, k=2)\n",
    "            rawMatches = []\n",
    "            for m,n in pairMatches:\n",
    "                if m.distance < 0.7*n.distance:\n",
    "                    rawMatches.append(m)\n",
    "        else:\n",
    "            bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "            rawMatches = bf.match(image_i_desc, image_1_desc)\n",
    "\n",
    "        sortMatches = sorted(rawMatches, key=lambda x: x.distance)\n",
    "        matches = sortMatches[0:128]\n",
    "\n",
    "        hom = findHomography(image_i_kp, image_1_kp, matches)\n",
    "        newimage = cv2.warpPerspective(images[i], hom, (images[i].shape[1], images[i].shape[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "        outimages.append(newimage)\n",
    "        # If you find that there's a large amount of ghosting, it may be because one or more of the input\n",
    "        # images gets misaligned.  Outputting the aligned images may help diagnose that.\n",
    "        # cv2.imwrite(\"aligned{}.png\".format(i), newimage)\n",
    "\n",
    "    return outimages\n",
    "\n",
    "#   Compute the gradient map of the image\n",
    "def doLap(image):\n",
    "\n",
    "    # YOU SHOULD TUNE THESE VALUES TO SUIT YOUR NEEDS\n",
    "    kernel_size = 5         # Size of the laplacian window\n",
    "    blur_size = 5           # How big of a kernal to use for the gaussian blur\n",
    "                            # Generally, keeping these two values the same or very close works well\n",
    "                            # Also, odd numbers, please...\n",
    "\n",
    "    blurred = cv2.GaussianBlur(image, (blur_size,blur_size), 0)\n",
    "    return cv2.Laplacian(blurred, cv2.CV_64F, ksize=kernel_size)\n",
    "\n",
    "#   This routine finds the points of best focus in all images and produces a merged result...\n",
    "def focus_stack(unimages):\n",
    "    images = align_images(unimages)\n",
    "\n",
    "    print(\"Computing the laplacian of the blurred images\")\n",
    "    laps = []\n",
    "    for i in range(len(images)):\n",
    "        print(\"Lap {}\".format(i))\n",
    "        laps.append(doLap(cv2.cvtColor(images[i],cv2.COLOR_BGR2GRAY)))\n",
    "\n",
    "    laps = np.asarray(laps)\n",
    "    print(\"Shape of array of laplacians = {}\".format(laps.shape))\n",
    "\n",
    "    output = np.zeros(shape=images[0].shape, dtype=images[0].dtype)\n",
    "    abs_laps = np.absolute(laps)\n",
    "    maxima = abs_laps.max(axis=0)\n",
    "    bool_mask = abs_laps == maxima\n",
    "    mask = bool_mask.astype(np.uint8)\n",
    "    for i in range(0,len(images)):\n",
    "        output = cv2.bitwise_not(images[i],output, mask=mask[i])\n",
    "\n",
    "    return 255-output, mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}